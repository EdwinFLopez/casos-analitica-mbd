{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Caso 3: Good Reads \n",
    "\n",
    "## Sección Tercera: Análisis Predictivo\n",
    "\n",
    "### Objetivos:\n",
    "\n",
    "1. Una editorial nos ha contactado para ver qué parámetros debería tener un libro para que fuera exitoso. A partir del dataset y su análisis, orienta a la editorial sobre qué parámetros deben seguir a la hora de publicar un nuevo libro.\n",
    "\n",
    "2. Diseña un modelo que, a partir de un libro de entrada, te recomiende una nueva lectura. Puedes utilizar o bien el dataset proporcionado o bien enriquecerlo (por ejemplo, utilizando técnicas de __webscrapping__, o añadiendo más atributos a los libros actuales).\n",
    " \n",
    "3. Respecto a este sistema, a modo de ejemplo, explica las recomendaciones que proporcionaría el modelo si entráramos los siguientes libros: \n",
    "* \"**A Court of Thorns and Roses**\" de __Sarah J. Maas__\n",
    "* \"**Hamlet**\" de __William Shakespeare__\n",
    "* \"**La Apología de Sócrates**\" de __Platón__\n",
    "\n",
    "### Metodología\n",
    "\n",
    "1. Procesamiento de herramientas de webscrapping para obtener la data del sitio \"**Good Reads**\". Estas herramientas son los archivos `get_books.py` y `get_books_from_list.py`, que fueron suministrados con el ejercicio.\n",
    "2. Agregar la data obtenida al dataset de good reads provisto por el ejercicio.\n",
    "3. Procesar los archivos de metadata que están en formato __JSON__ para construir los dataframes necesarios para hacer el modelo de predicción.\n",
    "4. Construir la matriz de similitud utilizando cosine_similarity\n",
    "5. Crear la función de predicción\n",
    "\n",
    "___"
   ],
   "id": "567cddd72b1bea99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Instalar dependencias",
   "id": "f9ddd0bbcdda123d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install -r ./../requirements.txt",
   "id": "537436bf00421065",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Obtenemos los archivos de metadata para mayo y junio 2024",
   "id": "9d5c7e4f5b1a5859"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python get_books_from_list.py --url_path https://www.goodreads.com/list/show/201106.Best_books_of_May_2024 --output_directory_path ./dataset/my_list_of_books_may.txt",
   "id": "615ff6be998e83b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python get_books_from_list.py --url_path https://www.goodreads.com/list/show/202186.Best_books_of_June_2024 --output_directory_path ./dataset/my_list_of_books_jun.txt",
   "id": "49d611f6014b429c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python get_books.py --book_ids_path ./dataset/my_list_of_books_may.txt --output_directory_path ./data/classic_book_metadata",
   "id": "aa6a84229da6fb84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python get_books.py --book_ids_path ./dataset/my_list_of_books_jun.txt --output_directory_path ./data/classic_book_metadata",
   "id": "62331da42809d9f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Descomprimimos el dataset LSGoodReads ",
   "id": "d61013dadbbb4366"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from caso03.descomprimir_dataset import unzip_dataset\n",
    "# Carga de datos\n",
    "# Cargar dataset y descomprimir en /datos\n",
    "unzip_dataset(\"./dataset/LSGoodReads.zip\",\"./data\")"
   ],
   "id": "2648d5d325d0ee35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Procesamos los archivos de metadata encontrados en __\"./data/classic_book_metadata\"__ y en __\"./data/LSGoodReads\"__\n",
    "\n",
    "Definimos los imports y las funciones de uso general"
   ],
   "id": "70cadeb91e884741"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def to_float(cell_value) -> float:\n",
    "    if type(cell_value) == str and cell_value.isnumeric():\n",
    "        return float(cell_value)\n",
    "    elif type(cell_value) == str and cell_value.find(\"k\") > -1:\n",
    "        return float(cell_value.replace('k', ''))*1000\n",
    "    elif type(cell_value) == int:\n",
    "        return float(cell_value)\n",
    "    return 0.0\n",
    "\n",
    "def clean_text(cell_value) -> str:\n",
    "    text = str(cell_value)                      # Convert the input text to string\n",
    "    text = text.strip()\n",
    "    text = text.lower()                         # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text)            # replace repeated blanks with a single one\n",
    "    text = re.sub(r' ', '-', text)              # replace blanks with '-'\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\-]', '', text)  # Remove special characters except for digits, letters and '-'\n",
    "    return text\n",
    "\n",
    "def list_to_str(a_list: list) -> str:\n",
    "    if type(a_list) is list:\n",
    "        another_list = sorted(a_list)\n",
    "        another_list = [ clean_text(cell_value) for cell_value in list(set(another_list)) ]\n",
    "        return \" \".join(another_list)\n",
    "    return \"\"\n",
    "\n",
    "def get_books_metadata(path_to_json: str) -> pd.DataFrame:\n",
    "    df = pd.read_json(path_to_json)\n",
    "    df.set_index('book_id', inplace=True)\n",
    "    \n",
    "    # Guardamos el título original\n",
    "    df['original_title'] = df['book_title'].apply(lambda title: str(title).strip())\n",
    "    \n",
    "    # Limpiamos textos\n",
    "    for column_name in ['book_title', 'author', 'book_language', 'format']:\n",
    "        df[column_name] = df[column_name].map(clean_text)            \n",
    "    \n",
    "    # Limpiar numéricos\n",
    "    for column_name in ['num_pages', 'num_ratings', 'num_reviews', 'year_first_published', 'people_curr_read', 'peop_want_to_read']:\n",
    "        df[column_name] = df[column_name].map(to_float)\n",
    "\n",
    "    # Limpiar listas\n",
    "    for column_name in ['book_series', 'book_settings', 'book_characters', 'genres', 'awards']:\n",
    "        df[column_name] = df[column_name].map(list_to_str)            \n",
    "\n",
    "    # Limpiar ratings in rating_distribution\n",
    "    df['positive_ratings'] = 0.0\n",
    "    df['negative_ratings'] = 0.0\n",
    "    for index, row in df.iterrows():\n",
    "        reviews = row['rating_distribution']\n",
    "        positive_ratings = 0.0\n",
    "        negative_ratings = 0.0\n",
    "        if reviews:\n",
    "            positive_ratings = float(reviews['5 Stars']) + float(reviews['4 Stars']) + float(reviews['3 Stars'])\n",
    "            negative_ratings = float(reviews['2 Stars']) + float(reviews['1 Star'])\n",
    "        df.loc[index, 'positive_ratings'] = positive_ratings\n",
    "        df.loc[index, 'negative_ratings'] = negative_ratings\n",
    "\n",
    "    # remove not needed columns\n",
    "    df.drop(['book_id_title', 'cover_image_uri', 'authorlink', 'rating_distribution'], inplace=True, axis=1)\n",
    "    return df"
   ],
   "id": "e10c73faeec4b77e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Exploramos los datos cargados de \"classic_book_metadata\"**",
   "id": "faaa7a2ac381f56e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classics_all_books_path = os.path.abspath(\n",
    "    os.path.join('./data/classic_book_metadata', 'all_books.json')\n",
    ")\n",
    "books_df = pd.DataFrame(get_books_metadata(classics_all_books_path))\n",
    "print(books_df.shape)\n",
    "print(books_df.dtypes)\n",
    "books_df.head(50)"
   ],
   "id": "2c77d200394f07b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Exploramos los libros de \"LSGoodReads\"**",
   "id": "e76bc92537c20cf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "goodreads_all_books_path = os.path.abspath(\n",
    "    os.path.join('./data/LSGoodReads', 'all_books.json')\n",
    ")\n",
    "books_df = pd.concat([books_df, pd.DataFrame(get_books_metadata(goodreads_all_books_path))]) \n",
    "print(books_df.shape)\n",
    "print(books_df.dtypes)\n",
    "books_df.head(100)"
   ],
   "id": "d0a417dd68333d18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Conclusiones de la exploración inicial\n",
    "Después de esta corta exploración, observamos que la data es de buena calidad, y es posible realizar los siguientes procesos.\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "### Exploración de datos."
   ],
   "id": "e1391f3d1a79d473"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Revisamos la distribución de las variables numéricas   \n",
    "books_df.hist(figsize = (10, 10))"
   ],
   "id": "f68bd0261ae7652e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Nos hacemos una idea general de las variables categóricas\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_word_cloud(text_column, column_name):\n",
    "    wordcloud = WordCloud(background_color='white').generate(' '.join(text_column.unique()))\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(column_name)\n",
    "    plt.show()\n",
    "\n",
    "for column_name in books_df.select_dtypes(include='object').columns.tolist():\n",
    "    generate_word_cloud(books_df[column_name], column_name)"
   ],
   "id": "6a3888dada4234dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "Preparamos la data para crear el tensor requerido para calcular la matriz de similitud del coseno"
   ],
   "id": "5351811e4b9f6266"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rellenamos los vacíos.\n",
    "for column_name in books_df.select_dtypes(include='number').columns:\n",
    "    books_df[column_name] = books_df[column_name].fillna(0.0)\n",
    "\n",
    "# Calculamos la bolsa de tokens para la matriz \n",
    "books_df['book_tokens'] = \"\"\n",
    "for index, row in books_df.iterrows():\n",
    "    data = [row[column_name] for column_name in books_df.select_dtypes(include=['object']).columns]\n",
    "    data = map(lambda tokens: re.sub(r'[\\-]', ' ', tokens), data) \n",
    "    cell = \" \".join([item for item in data if item != \"\"])\n",
    "    books_df.loc[index, 'book_tokens'] = cell.strip()\n",
    "\n",
    "books_df[['book_title','book_tokens']].head(10)\n"
   ],
   "id": "2ccce693d5104bb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creamos las funciones para obtener la metadata a partir del título\n",
    "def get_book_id_by_title(df: pd.DataFrame, book_title:str) -> int|None:\n",
    "    # probar primero contra título original:\n",
    "    book_index = df.index[df['original_title'] == book_title].tolist()\n",
    "    if book_index:\n",
    "        return book_index[0]    \n",
    "    # Luego contra el título preprocesado    \n",
    "    title_transformed = clean_text(book_title)\n",
    "    book_index = df.index[df['book_title'] == title_transformed].tolist()\n",
    "    if book_index:\n",
    "        return book_index[0]\n",
    "    # No se encontró\n",
    "    return None\n",
    "\n",
    "def get_book_original_title_by_id(df: pd.DataFrame, book_id:int) -> str|None:\n",
    "    if not df.loc[book_id].empty:\n",
    "        return df.loc[book_id]['original_title']\n",
    "    return None\n",
    "\n",
    "def get_book_title_by_id(df: pd.DataFrame, book_id:int) -> str|None:\n",
    "    if not df.loc[book_id].empty:\n",
    "        return df.loc[book_id]['book_title']\n",
    "    return None"
   ],
   "id": "74a03f52532cb5bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Probamos las funciones creadas con:\n",
    "#   \"A Court of Thorns and Roses\" de Sarah J. Maas\n",
    "#   \"Hamlet\" de William Shakespeare\n",
    "#   \"La Apología de Sócrates\" de Platón\n",
    "\n",
    "print(clean_text(\"A Court of Thorns and Roses\"))\n",
    "print(clean_text(\"Hamlet\"))\n",
    "print(clean_text(\"La Apologia de Socrates\"))\n",
    "print(clean_text(\"La Apología de Sócrates\"))\n",
    "\n",
    "print(get_book_id_by_title(books_df, \"A Court of Thorns and Roses\"))\n",
    "print(get_book_id_by_title(books_df, \"La Apologia de Socrates\"))\n",
    "print(get_book_id_by_title(books_df, \"La Apología de Sócrates\"))\n",
    "print(get_book_id_by_title(books_df, \"Hamlet\"))\n",
    "print(get_book_original_title_by_id(books_df, 1420))\n",
    "books_df.query(f\"original_title=='Hamlet'\")"
   ],
   "id": "2f0410543f6e8a34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculamos el tensor de la variable categórica: 'book_tokens' como matriz dispersa:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "categorical_attrs_df = books_df['book_tokens'].copy()\n",
    "tfidf_vectorizer=TfidfVectorizer()\n",
    "tfidf_vectors=tfidf_vectorizer.fit_transform(categorical_attrs_df)"
   ],
   "id": "70c766e9980583d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Características de la variable categórica 'book_tokens' por book_id.\n",
    "tensor_categorical_df = pd.DataFrame(\n",
    "    tfidf_vectors.todense(),\n",
    "    index=categorical_attrs_df.index,\n",
    "    columns=tfidf_vectorizer.get_feature_names_out()\n",
    ")\n",
    "tensor_categorical_df.head()"
   ],
   "id": "e0d6c59c17b3f60f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Obtenemos una copia de las variables numéricas para calcular el tensor.\n",
    "numerical_columns = [column_name for column_name in books_df.select_dtypes(include=['Float64']).columns]\n",
    "number_attrs_df = books_df[numerical_columns].copy()\n",
    "number_attrs_df.head()"
   ],
   "id": "f54415a970bd2531",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculamos el vector normalizado de las variables numéricas que se utilizará para calcular \n",
    "# la matriz de similitud.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_scaler = StandardScaler()\n",
    "numerical_vectors = numerical_scaler.fit_transform(number_attrs_df)\n",
    "tensor_numerical_df = pd.DataFrame(\n",
    "    numerical_vectors,\n",
    "    index=number_attrs_df.index,\n",
    "    columns=number_attrs_df.columns\n",
    ")\n",
    "tensor_numerical_df.head()"
   ],
   "id": "909b5427c31a3d19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Combinamos las dos matrices de características vectorizadas para construir la matriz de similitud.\n",
    "similarity_tensors_df = tensor_numerical_df.merge(tensor_categorical_df, left_index=True, right_index=True)\n",
    "similarity_tensors_df.head()"
   ],
   "id": "c830b5c6035e6add",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Grabamos el dataset de los tensores para calcular la matriz de similaridad\n",
    "similarity_tensors_df.to_parquet(\"./dataset/similarity_tensors.parquet\", compression=\"gzip\")"
   ],
   "id": "9c319311628f954c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Finalmente, calculamos la matriz de similitud utilizando el ángulo del coseno entre tensores:\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(similarity_tensors_df, similarity_tensors_df)\n",
    "similarity_matrix_df = pd.DataFrame(similarity_matrix, index=similarity_tensors_df.index, columns=similarity_tensors_df.index)\n",
    "similarity_matrix_df.head()"
   ],
   "id": "461b29ac408d7cda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Grabamos el dataset de la matriz de similaridad\n",
    "similarity_matrix_df.to_csv(\"./dataset/similarity_matrix.csv\", compression=\"gzip\")"
   ],
   "id": "4eb381eb199a727e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Definimos las funciones para el cálculo de recomendaciones:\n",
    "\n",
    "def get_book_recommendations_by_id(\n",
    "        books_df: pd.DataFrame,\n",
    "        similarity_matrix_df: pd.DataFrame, \n",
    "        book_id: int,\n",
    "        recommendations: int\n",
    ") -> pd.DataFrame:\n",
    "    if book_id not in books_df.index.tolist():\n",
    "        return []\n",
    "    book_similarities = list(enumerate(similarity_matrix_df[book_id]))\n",
    "    book_similarities = sorted(book_similarities, key=lambda x: x[1], reverse=True)\n",
    "    most_similar_books = book_similarities[1:1+recommendations]\n",
    "    book_indices = [i[0] for i in most_similar_books] \n",
    "    return books_df[['original_title', 'author']].iloc[book_indices]\n",
    "\n",
    "def get_book_recommendations_by_title(\n",
    "        books_df: pd.DataFrame, \n",
    "        similarity_matrix_df: pd.DataFrame, \n",
    "        book_title: str,\n",
    "        recommendations: int\n",
    ") -> pd.DataFrame:\n",
    "    book_id = get_book_id_by_title(books_df, book_title)\n",
    "    return get_book_recommendations_by_id(books_df, similarity_matrix_df, book_id, recommendations)"
   ],
   "id": "e8d629548d0064b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Stefan Zweig: Beware of Pity\n",
    "# Oscar Wilde: The picture of Dorian Gray\n",
    "# George Orwell: 1984\n",
    "\n",
    "get_book_recommendations_by_title(books_df, similarity_matrix_df, \"Beware of Pity\", 10)\n",
    "books_df[books_df['book_title'].str.contains('1984')]"
   ],
   "id": "a61a08a516802aff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_book_recommendations_by_title(books_df, similarity_matrix_df, \"The picture of Dorian Gray\", 10)",
   "id": "e34d17b34769c1d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_book_recommendations_by_title(books_df, similarity_matrix_df, \"1984\", 10)",
   "id": "25717a087c9cb206",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pregunta 1:\n",
    "\n",
    "Una editorial nos ha contactado para ver qué parámetros debería tener un libro para que fuera **exitoso**. A partir del dataset y su análisis, orienta a la editorial sobre qué parámetros deben seguir a la hora de publicar un nuevo libro.\n",
    "\n",
    "**Enfoque de Solución**\n",
    "Listamos los libros más exitosos como: \n",
    "* los que tienen positive_ratings >= mediana, \n",
    "* los que tienen premios (awards), \n",
    "* los que tienen average_rating >= media.\n",
    "\n",
    "A partir de ese conjunto de datos, buscamos las características comunes en:\n",
    "* Géneros\n",
    "* Formato\n",
    "* Autor\n",
    "* Idioma\n",
    "* Promedio de Num. de Páginas"
   ],
   "id": "58bcedabc397ba36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Búsqueda de datos a través de filtros\n",
    "positives_df = books_df[books_df['positive_ratings'] >= books_df['positive_ratings'].median()]\n",
    "awarded_df = books_df[books_df['awards'].notna() & books_df['awards'] != \"\"]\n",
    "ratings_df = books_df[books_df['average_rating'] > 3.5]\n",
    "\n",
    "# Unión de resultados\n",
    "successful_books_df = pd.concat([positives_df, awarded_df, ratings_df], ignore_index=True, verify_integrity=True)\n",
    "successful_books_df.sort_values(by=['awards','positive_ratings','average_rating'], axis='rows', ascending=False, inplace=True)\n",
    "\n",
    "# Encontramos las modas\n",
    "top_100_df = successful_books_df[['genres','format','author','book_language','num_pages']].head(100)"
   ],
   "id": "bd99b9de91dd53b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "top_genres = top_100_df['genres'].tolist()\n",
    "top_genres = list(set(top_genres))\n",
    "top_genres = \" \".join(top_genres).split(\" \")\n",
    "Counter(top_genres).most_common(10)"
   ],
   "id": "419b1925703572ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_formats = top_100_df['format'].tolist()\n",
    "Counter(top_formats).most_common(3)"
   ],
   "id": "386a57d94e6161a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_authors = top_100_df['author'].tolist()\n",
    "Counter(top_authors).most_common(5)"
   ],
   "id": "a3f332b3933c47bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_languages = top_100_df['book_language'].tolist()\n",
    "Counter(top_languages).most_common(3)"
   ],
   "id": "7edfef9d1725a687",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean_numpages = top_100_df['num_pages'].median()\n",
    "devstd_numpages = top_100_df['num_pages'].std()\n",
    "[devstd_numpages, mean_numpages] "
   ],
   "id": "b6fe9dba0e45048d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pregunta 2:\n",
    "Obtenemos las recomendaciones de los libros:\n",
    "\n",
    "   * **\"A Court of Thorns and Roses\" de Sarah J. Maas**: NO está en la lista\n",
    "   * **\"La Apología de Sócrates\" de Platón**: NO está en la lista\n",
    "   * **\"Hamlet\" de William Shakespeare**: SI está en la lista"
   ],
   "id": "14527a649d1c8b86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "{\n",
    "    \"A Court of Thorns and Roses\": get_book_recommendations_by_title(books_df, similarity_matrix_df, \"A Court of Thorns and Roses\", 10),\n",
    "    \"La Apologia de Socrates\": get_book_recommendations_by_title(books_df, similarity_matrix_df, \"La Apologia de Socrates\", 10),\n",
    "    \"La Apología de Sócrates\": get_book_recommendations_by_title(books_df, similarity_matrix_df, \"La Apología de Sócrates\", 10),\n",
    "    \"Hamlet\": get_book_recommendations_by_title(books_df, similarity_matrix_df, \"Hamlet\", 10)\n",
    "}"
   ],
   "id": "edcf4d99486f4a07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "books_df[books_df['author']=='plato']",
   "id": "d9d28e629cb8935e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "books_df[books_df['book_title'].str.contains('socrates')]",
   "id": "81293887f71769",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fd2592d794fe2ae6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
