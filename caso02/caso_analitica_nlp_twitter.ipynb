{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a08636",
   "metadata": {},
   "source": [
    "# **Caso de Analítica - NLP Twitter**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb88c06501c040",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este Caso 2 debes realizar un análisis sentimental, sintáctico y gramatical de comentarios Twitter. La base de datos la puedes descargar desde eStudy (Caso 3 dataset), la cual contiene un CSV de mensajes enviados a Twitter con las siguientes columnas:\n",
    "\n",
    "1. Puntuación sentimental o polaridad (-5 = negativa ... 0 = neutral ... 5 = positiva) (por calcular)\n",
    "2. Id del tweet\n",
    "3. Fecha del tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "4. Búsqueda. Si no hay búsqueda, el valor es NO_QUERY\n",
    "5. Usuario que ha tweeteado\n",
    "6. Texto del tweet\n",
    "\n",
    "Con estos datos se os propone que apliquéis técnicas analíticas y de visualización para responder a las siguientes preguntas. No hay restricciones acerca de las técnicas ni tecnologías a utilizar siempre y cuando los resultados sean reproducibles y estén debidamente justificados. No obstante, las siguientes librerías y códigos de ejemplo os pueden ser muy útiles para responderlas:\n",
    "\n",
    "> **_Librería NLTK:_** [https://www.nltk.org/install.html]()\n",
    ">  \n",
    "> **Propósito**: \n",
    "> Trabajar con datos en lenguaje humano.\n",
    "\n",
    "> **_Librería texstat:_** [https://pypi.org/project/textstat]()\n",
    ">  \n",
    "> **Propósito**: \n",
    "> Calcular estadística a partir de datos en lenguaje humano.\n",
    "\n",
    "---\n",
    "\n",
    "### Unsupervised-Text-Clustering using Natural Language Processing (NLP)\n",
    "\n",
    "Para realizar un conglomerado analítico de un corpus documental/textos se acostumbra a seguir los siguientes pasos genéricos. La técnica consiste en crear un vector cuantitativo a partir de los textos, previa limpieza y transformación, para aplicar técnicas de conglomerado:\n",
    "\n",
    "1. Eliminar caracteres de puntuación, espacios adicionales, dígitos u otros caracteres que puedan entorpecer el análisis textual\n",
    "2. Tokenizar y eliminar Stopwords. Se requiere un diccionario de palabras para quitar aquellas que puedan entorpecer el análisis textual. Por ejemplo, se puede utilizar **“from nltk.corpus import stopwords”. Ejemplo: NLTK stop words - Python Tutorial (pythonspot.com)**\n",
    "3. Encontrar la raíz de las palabras aplicando **lemmatization o stemming**.\n",
    "4. Aplicar vectorizado del tokenizado para calcular apariciones de los tokens y cuantificar los tweets. Se pueden usar distintos cálculos, por ejemplo **Bag-of-Words, Word2Vec, o TFIDF** con **“from\n",
    "sklearn.feature_extraction.text import TfidfVectorizer”**\n",
    "5. Aplicar clustering con técnicas adecuadas. Por ejemplo, Kmeans previo cálculo del número de clusters con técnicas como Elbow.\n",
    "\n",
    "---\n",
    "\n",
    "### Análisis de sentimientos en Python - Transformers\n",
    "Huggingface pone a disposición una manera muy asequible de realizar análisis sentimentales con modelos pre-entrenados. \n",
    "\n",
    "Sigue estos dos enlaces para poder realizar las preguntas extras del caso:\n",
    "1. [Getting Started with Sentiment Analysis using Python](https://huggingface.co/blog/sentiment-analysis-python) \n",
    "2. [Pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines)\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Librerías Necesarias"
   ],
   "id": "45543ed5114c2431"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import textstat\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from caso02.descomprimir_dataset import unzip_dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "586b8c81bbfcc109",
   "metadata": {},
   "source": [
    "# Carga de datos\n",
    "# Cargar dataset y descomprimir en /datos\n",
    "csv_dataset_path = unzip_dataset()\n",
    "print(csv_dataset_path)\n",
    "\n",
    "tweets_df = pd.read_csv(csv_dataset_path)\n",
    "tweets_muestra = tweets_df.sample(n=50000)\n",
    "tweets_df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Descarga de recursos necesarios de NLTK\n",
    "Iniciamos la ruta dentro de \"./data/nltk_data\" relativa al proyecto.\n",
    "Debe ser antes del import de la librería para que tenga efecto.\n",
    "Por defecto, se usa en la ruta del usuario, lo que puede ser problemático en otras instalaciones y proyectos."
   ],
   "id": "bda63680547bc426"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Descarga de recursos necesarios de NLTK\n",
    "os.environ[\"NLTK_DATA\"]=os.path.abspath('./data/nltk_data')\n",
    "import  nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.data.path.append(os.path.abspath('./data/nltk_data'))\n",
    "nltk.download('punkt', download_dir=os.path.abspath('./data/nltk_data'))\n",
    "nltk.download('stopwords', download_dir=os.path.abspath('./data/nltk_data'))\n",
    "nltk.download('wordnet', download_dir=os.path.abspath('./data/nltk_data'))\n",
    "nltk.download('omw-1.4', download_dir=os.path.abspath('./data/nltk_data'))\n",
    "nltk.download('words', download_dir=os.path.abspath('./data/nltk_data'))"
   ],
   "id": "7eb60f3b3cd512fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Pre-Procesamiento de los datos"
   ],
   "id": "d70ef5b6ce59e327"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Asignamos nombres a columnas del Dataset",
   "id": "fbe0c7ef0075c9fb"
  },
  {
   "cell_type": "code",
   "id": "9de5b053e6aeaf8f",
   "metadata": {},
   "source": [
    "# Otros Códigos\n",
    "tweets_df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "tweets_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Eliminamos la Columna 'flag' debido a que no aporta información relevante",
   "id": "65b603e0f1dfdac1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tweets_df = tweets_df.drop('flag', axis=1)",
   "id": "eae4983ef8e6ccd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Realizamos una limpieza de los datos utilizando técnicas de conglomerado. Cada paso está numerado en su respectiva función, como se muestra a continuación:\n",
    "1. Eliminar caracteres de puntuación, espacios adicionales, dígitos u otros caracteres que puedan entorpecer\n",
    "el análisis textual\n",
    "2. Tokenizar y eliminar Stopwords. Se requiere un diccionario de palabras para quitar aquellas que puedan\n",
    "entorpecer el análisis textual. Por ejemplo, se puede utilizar “from nltk.corpus import stopwords”. Ejemplo:\n",
    "NLTK stop words - Python Tutorial (pythonspot.com)\n",
    "3. Encontrar la raíz de las palabras aplicando lemmatization o stemming.\n",
    "4. Aplicar vectorizado del tokenizado para calcular apariciones de los tokens y cuantificar los tweets. Se\n",
    "pueden usar distintos cálculos, por ejemplo Bag-of-Words, Word2Vec, o TFIDF con “from\n",
    "sklearn.feature_extraction.text import TfidfVectorizer”\n",
    "5. Aplicar clustering con técnicas adecuadas. Por ejemplo, Kmeans previo cálculo del número de clusters con\n",
    "técnicas como Elbow."
   ],
   "id": "2d23dbe9b7f72cc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#1.\n",
    "def limpieza_datos(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[^\\w\\s@]', '', text)  # Mantener los @\n",
    "    text = text.strip() \n",
    "    return text\n",
    "\n",
    "#Aplicamos la funcion Limpieza de Datos en el Dataset\n",
    "tweets_df['text'] = tweets_df['text'].apply(limpieza_datos)\n",
    "\n",
    "#Printamos los Datos para visualizar la limpieza\n",
    "tweets_df.head(100)"
   ],
   "id": "bf55d8f1b2aa4018",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#2.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def tokenizar_y_eliminar_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens_filtrados = [word for word in tokens if word not in stop_words]\n",
    "    return tokens_filtrados\n",
    "\n",
    "#Aplicamos la función sobre el dataset\n",
    "tweets_df['tokens'] = tweets_df['text'].apply(tokenizar_y_eliminar_stopwords)"
   ],
   "id": "d649c2554b461d10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#3.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "#Aplicamos la función sobre el dataset\n",
    "tweets_df['lemmatized_tokens'] = tweets_df['tokens'].apply(lemmatize_tokens)"
   ],
   "id": "bcf40ecaf9425934",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#4.\n",
    "tweets_df['processed_text'] = tweets_df['lemmatized_tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(tweets_df['processed_text'])"
   ],
   "id": "f9b95f76be1e7734",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#5.\n",
    "def metodo_elbow(X):\n",
    "    wcss = []\n",
    "    for i in range(1, 11):\n",
    "        kmeans = KMeans(n_clusters=i, max_iter=300, n_init=10, random_state=0)\n",
    "        kmeans.fit(X)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    plt.plot(range(1, 11), wcss)\n",
    "    plt.title('Método del codo')\n",
    "    plt.xlabel('Número de clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.show()\n",
    "\n",
    "metodo_elbow(X)\n",
    "kmeans = KMeans(n_clusters=3, max_iter=300, n_init=10, random_state=0)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "tweets_df['cluster'] = clusters\n",
    "tweets_df.head()"
   ],
   "id": "48c78b7461b78f9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f58f3eaa405084f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5a1ac6466749d",
   "metadata": {},
   "source": [
    "### 1. ¿Cuál es la distribución de las polaridades y complejidad de lectura/escritura de los tweets en el dataset?\n",
    "\n",
    "#### 1.a. ¿Hay una mayor cantidad de tweets positivos, negativos o neutrales?\n",
    "\n",
    "#### 1.b. ¿Cómo se relacionan las distintas polaridades según la complejidad de lectura/escritura de los tweets?"
   ]
  },
  {
   "cell_type": "code",
   "id": "12ef9e4b76081904",
   "metadata": {},
   "source": [
    "#1.a\n",
    "\n",
    "def calcular_polarity(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity * 5\n",
    "\n",
    "tweets_df['polarity'] = tweets_df['text'].apply(calcular_polarity)\n",
    "\n",
    "polarity_counts = tweets_df['polarity'].value_counts(bins=10, sort=False)\n",
    "print(polarity_counts)\n",
    "\n",
    "polarity_counts.plot(kind='bar', title='Distribución de las Polaridades de los Tweets')\n",
    "plt.xlabel('Polaridad')\n",
    "plt.ylabel('Cantidad de Tweets')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#1.b\n",
    "\n",
    "def calcular_readability(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "tweets_df['readability'] = tweets_df['text'].apply(calcular_readability)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.boxplot(x=pd.cut(tweets_df['polarity'], bins=10), y='readability', data=tweets_df)\n",
    "plt.title('Relación entre Polaridad y Complejidad de Lectura de los Tweets')\n",
    "plt.xlabel('Polaridad')\n",
    "plt.ylabel('Complejidad de Lectura')\n",
    "plt.show()\n",
    "\n",
    "tweets_df.head(100)"
   ],
   "id": "15df0463515bc6aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "78bad1a751968c25",
   "metadata": {},
   "source": [
    "### 2. ¿Existen patrones gramaticales o sintácticos comunes en los tweets con polaridad positiva o negativa? Por ejemplo, puede que los tweets positivos tiendan a utilizar más palabras de agradecimiento o elogios, mientras que los tweets negativos utilizan más palabras de crítica o enojo."
   ]
  },
  {
   "cell_type": "code",
   "id": "2f2b7d68a71f23cd",
   "metadata": {},
   "source": [
    "#2.\n",
    "tweets_positivos = tweets_df[tweets_df['polarity'] > 0]\n",
    "tweets_negativos = tweets_df[tweets_df['polarity'] < 0]\n",
    "\n",
    "frecuencia_palabras_positivas = Counter([word for tokens in tweets_positivos['lemmatized_tokens'] for word in tokens])\n",
    "\n",
    "frecuencia_palabras_negativas = Counter([word for tokens in tweets_negativos['lemmatized_tokens'] for word in tokens])\n",
    "\n",
    "palabras_comunes_positivas = frecuencia_palabras_positivas.most_common(20)\n",
    "palabras_comunes_negativas = frecuencia_palabras_negativas.most_common(20)\n",
    "\n",
    "df_palabras_positivas = pd.DataFrame(palabras_comunes_positivas, columns=['Palabra', 'Frecuencia'])\n",
    "df_palabras_negativas = pd.DataFrame(palabras_comunes_negativas, columns=['Palabra', 'Frecuencia'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Graficamos las palabras más comunes en tweets positivos\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Frecuencia', y='Palabra', data=df_palabras_positivas)\n",
    "plt.title('Palabras más comunes dentro de los Tweets Positivos')\n",
    "plt.show()\n",
    "\n",
    "#Graficamos las palabras más comunes en tweets negativos\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Frecuencia', y='Palabra', data=df_palabras_negativas)\n",
    "plt.title('Palabras más comunes dentro de los Tweets Negativos')\n",
    "plt.show()"
   ],
   "id": "c668ad01c2aea11",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f628391a40fe7710",
   "metadata": {},
   "source": [
    "### 3.  ¿Qué usuarios tienden a generar tweets con una polaridad más positiva o negativa? ¿Hay alguna relación entre la polaridad de los tweets y el número de seguidores de un usuario?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tweets_muestra.columns = ['id', 'polarity', 'timestamp', 'query', 'user', 'text']\n",
    "tweets_muestra['followers_count'] = tweets_muestra['text'].str.count('@')\n",
    "print(tweets_muestra.head())"
   ],
   "id": "e70cfeb2145939b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Calcular la polaridad promedio por usuario\n",
    "polaridad_promedio_por_usuario = tweets_muestra.groupby('user')['polarity'].mean()\n",
    "polaridad_promedio_por_usuario = polaridad_promedio_por_usuario.sort_values()\n",
    "\n",
    "print(\"Usuarios con la polaridad más positiva:\")\n",
    "print(polaridad_promedio_por_usuario.tail())\n",
    "\n",
    "print(\"\\nUsuarios con la polaridad más negativa:\")\n",
    "print(polaridad_promedio_por_usuario.head())"
   ],
   "id": "7d6270d34751776b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Calculamos la correlación entre la polaridad promedio y el número de seguidores\n",
    "correlacion = tweets_muestra.groupby('user').agg({'polarity': 'mean', 'followers_count': 'mean'})\n",
    "\n",
    "#Se grafica el diagrama de dispersión\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(correlacion['polarity'], correlacion['followers_count'], color='orange', alpha=0.4)\n",
    "plt.title('Relación entre Polaridad de Tweets y Número de Seguidores')\n",
    "plt.xlabel('Polaridad Promedio de Tweets')\n",
    "plt.ylabel('Número de Seguidores')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "82ab49617a916025",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Interpretación de Resultados:\n",
    "\n",
    "- El resultado de la gráfica de dispersión nos indica que la polaridad de los tweets (si son más positivos o negativos) no tiene un impacto directo en la cantidad de seguidores que un usuario puede tener en este conjunto de datos.\n",
    "\n",
    "- Otros factores como la relevancia del contenido, la interacción con otros usuarios, la frecuencia de publicación y la popularidad previa pueden influir más en el número de seguidores de un usuario en esta muestra."
   ],
   "id": "50d3f838d11c72cb"
  },
  {
   "cell_type": "markdown",
   "id": "b6b66c3946de5df0",
   "metadata": {},
   "source": [
    "### 4. ¿Hay alguna palabra o conjunto de palabras específicas que estén asociadas con tweets de polaridad extrema?\n",
    "\n",
    "#### 4.a. ¿Estas palabras son más comunes en tweets sobre un tema en particular o están distribuidas en todo el dataset?\n",
    "\n",
    "#### 4.b. Escoge un tema y clusteriza los usuarios según polaridades."
   ]
  },
  {
   "cell_type": "code",
   "id": "1d503f8a973fccc9",
   "metadata": {},
   "source": [
    "#4.a\n",
    "tweets_extremos = tweets_df[(tweets_df['polarity'] == 5) | (tweets_df['polarity'] == -5)]\n",
    "\n",
    "#Se identifican las frecuencias de palabras en los tweets con polaridad extrema\n",
    "frecuencia_palabras_extremas = Counter([word for tokens in tweets_extremos['lemmatized_tokens'] for word in tokens])\n",
    "palabras_comunes_extremas = frecuencia_palabras_extremas.most_common(20)\n",
    "\n",
    "df_palabras_extremas = pd.DataFrame(palabras_comunes_extremas, columns=['Palabra', 'Frecuencia'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Frecuencia', y='Palabra', data=df_palabras_extremas)\n",
    "plt.title('Palabras más comunes en Tweets con polaridad Extrema')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Se aplicó el algoritmo KMeans para agrupar a los usuarios en clusters y se visualizó la distribución de usuarios en función de la polaridad de sus publicaciones y la complejidad de lectura mediante un ScatterPlot.",
   "id": "8a486f6ec1b7e456"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#4.b\n",
    "tweets_df['tema_love'] = tweets_df['processed_text'].apply(lambda text: 1 if 'love' in text else 0)\n",
    "usuarios_love = tweets_df[tweets_df['tema_love'] == 1]\n",
    "\n",
    "# Vectorizamos los tweets sobre 'love'\n",
    "X_love = vectorizer.fit_transform(usuarios_love['processed_text'])\n",
    "\n",
    "# Clustering con KMeans \n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "usuarios_love['cluster'] = kmeans.fit_predict(X_love)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='polarity', y='readability', hue='cluster', data=tweets_df, palette='viridis')\n",
    "plt.title('Clustering de los usuarios según sus polaridades')\n",
    "plt.xlabel('Polaridad')\n",
    "plt.ylabel('Complejidad de lectura')\n",
    "plt.show()\n",
    "\n",
    "tweets_df[['user', 'polarity', 'cluster']].head(50)"
   ],
   "id": "168b3315195527a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14e1e3a28d838f58",
   "metadata": {},
   "source": [
    "### 5. ¿Hay alguna correlación entre la polaridad de un tweet y la fecha en que se publicó?\n",
    "\n",
    "#### 5.a. ¿Los tweets publicados durante ciertos períodos de tiempo tienden a ser más positivos o negativos que otros?"
   ]
  },
  {
   "cell_type": "code",
   "id": "dbccba39f5e74d3c",
   "metadata": {},
   "source": [
    "tweets_df['date'] = pd.to_datetime(tweets_df['date'])\n",
    "\n",
    "#Agrupamos fechas por día y calculamos la polaridad promedio\n",
    "polaridad_total = tweets_df.resample('D', on='date')['polarity'].mean().reset_index()\n",
    "\n",
    "#Se grafica la polaridad promedio a lo largo del tiempo para una análisis general \n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.lineplot(data=polaridad_total, x='date', y='polarity', marker='o')\n",
    "plt.title('Polaridad promedio Tweets en el tiempo')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Polaridad promedio')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Agrupamos por mes y se calcula la polaridad promedio\n",
    "polaridad_mensual = tweets_df.resample('ME', on='date')['polarity'].mean().reset_index()\n",
    "\n",
    "#Se grafica la polaridad promedio mes a mes para análisis exhaustivo\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.lineplot(data=polaridad_mensual, x='date', y='polarity', marker='o')\n",
    "plt.title('Polaridad promedio Tweets por Mes')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Polaridad promedio')\n",
    "plt.show()"
   ],
   "id": "77edea09eebd42e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e7f23ef4bf2074d4",
   "metadata": {},
   "source": [
    "### 6. Identifica los \"Top 10 Trolls\" y los \"Top 10 Influencers\". Justifica las características de un usuario Troll e Influencer."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Para identificar a los Trolls e Influencer debemos tener en cuenta las siguientes características:\n",
    "- Trolls:\n",
    "    - Generan una gran cantidad de tweets con polaridad negativa.\n",
    "    - Pueden tener un alto número de menciones negativas en sus tweets.\n",
    "\n",
    "- Influencers:\n",
    "    - Tienen un alto número de seguidores.\n",
    "    - Generan una gran cantidad de tweets con polaridad positiva.\n",
    "    - Sus tweets tienden a ser compartidos o mencionados con frecuencia en un contexto positivo. "
   ],
   "id": "1c1109e271196964"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Calculamos la polaridad promedio por usuario\n",
    "polaridad_promedio_por_usuario = tweets_muestra.groupby('user')['polarity'].mean()\n",
    "seguidores_por_usuario = tweets_muestra.groupby('user')['followers_count'].max()\n",
    "\n",
    "#Ordenamos los usuarios por polaridad promedio y número de seguidores\n",
    "polaridad_promedio_por_usuario = polaridad_promedio_por_usuario.sort_values(ascending=False)\n",
    "seguidores_por_usuario = seguidores_por_usuario.loc[polaridad_promedio_por_usuario.index]\n",
    "\n",
    "#Top 10 Influencers por número de seguidores\n",
    "top_influencers = seguidores_por_usuario.head(10)\n",
    "\n",
    "#Top 10 Trolls por polaridad promedio\n",
    "top_trolls = polaridad_promedio_por_usuario.head(10)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Top 10 Influencers:\")\n",
    "print(top_influencers)\n",
    "\n",
    "print(\"\\nTop 10 Trolls:\")\n",
    "print(top_trolls)"
   ],
   "id": "9f125c2289ee6c66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_trolls = polaridad_promedio_por_usuario.head(10)\n",
    "top_influencers = seguidores_por_usuario.head(10)\n",
    "\n",
    "#Graficamos\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "#Top 10 Trolls\n",
    "ax1.barh(top_trolls.index, top_trolls.values, color='salmon')\n",
    "ax1.set_xlabel('Polaridad Promedio')\n",
    "ax1.set_title('Top 10 Trolls: Polaridad Promedio de Tweets')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "#Top 10 Influencers\n",
    "ax2.barh(top_influencers.index, top_influencers.values, color='lightgreen')\n",
    "ax2.set_xlabel('Número de Seguidores')\n",
    "ax2.set_title('Top 10 Influencers: Número de Seguidores')\n",
    "ax2.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "1bb9db7f34ae3474",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1f17a8a2d03c9a1d",
   "metadata": {},
   "source": [
    "### 7. Extra: Utiliza Transformers con el pipeline de Huggingface para calcular la polaridad de los tweets y comparar los resultados de la pregunta 1."
   ]
  },
  {
   "cell_type": "code",
   "id": "e423d5f5f22875",
   "metadata": {},
   "source": [
    "# Respuesta\n",
    "from transformers import pipeline\n",
    "\n",
    "# Creamos un analisis de sentimientos usando el pipeline\n",
    "nlp = pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "resultados_analisis_sentimientos = nlp(tweets_df['text'].tolist())\n",
    "\n",
    "\n",
    "\n",
    "# Display the DataFrame with sentiment analysis results\n",
    "#tweets_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "539273f6712890cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c70e1e73486a63e",
   "metadata": {},
   "source": [
    "### 1. ¿Cómo se distribuyen los tweets según su polaridad a lo largo del tiempo?"
   ]
  },
  {
   "cell_type": "code",
   "id": "bb41765e4896664d",
   "metadata": {},
   "source": [
    "tweets_df['date'] = pd.to_datetime(tweets_df['date'])\n",
    "tweets_df['month'] = tweets_df['date'].dt.to_period('M')\n",
    "polaridad_mensual = tweets_df.groupby('month')['polarity'].mean().reset_index()\n",
    "polaridad_mensual['month'] = polaridad_mensual['month'].dt.to_timestamp()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(polaridad_mensual['month'], polaridad_mensual['polarity'], marker='o', linestyle='-', color='b')\n",
    "plt.title('Distribución de la polaridades de los Tweets a lo largo del tiempo')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Promedio polaridad')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dc9d2d0721f24a61",
   "metadata": {},
   "source": [
    "### 2. Visualiza el análisis sintáctico (número de palabras, frase, verbos, nombres...) de los top 10 Trolls e Influencers."
   ]
  },
  {
   "cell_type": "code",
   "id": "d4b861e3498abd2",
   "metadata": {},
   "source": [
    "# Respuesta\n",
    "print(\"Respuestas\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8ee0e1e923f228f5",
   "metadata": {},
   "source": [
    "### 3. ¿Existe alguna correlación entre el número de seguidores de un usuario y la polaridad de sus tweets? Representa visualmente esta relación."
   ]
  },
  {
   "cell_type": "code",
   "id": "32d06e566272841",
   "metadata": {},
   "source": [
    "polaridad_promedio_por_usuario = tweets_muestra.groupby('user')['polarity'].mean()\n",
    "seguidores_por_usuario = tweets_muestra.groupby('user')['followers_count'].max()\n",
    "\n",
    "df_correlacion = pd.DataFrame({'polarity': polaridad_promedio_por_usuario, 'followers_count': seguidores_por_usuario})\n",
    "correlacion = df_correlacion.corr()\n",
    "\n",
    "coeficiente_correlacion = correlacion.loc['polarity', 'followers_count']\n",
    "print(f\"Coeficiente de correlación: {coeficiente_correlacion}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_correlacion, x='followers_count', y='polarity', color='blue', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Número de Seguidores')\n",
    "plt.ylabel('Polaridad Promedio de los Tweets')\n",
    "plt.title('Relación entre el Número de Seguidores y la Polaridad de los Tweets')\n",
    "\n",
    "sns.regplot(data=df_correlacion, x='followers_count', y='polarity', scatter=False, color='red')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "9a0ddf803d8b1a33",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f28e12a33c7b081d",
   "metadata": {},
   "source": [
    "### 4. Crea una nube de palabras para cada polaridad."
   ]
  },
  {
   "cell_type": "code",
   "id": "2d39a83bb792305c",
   "metadata": {},
   "source": [
    "tweets_positivos = tweets_df[tweets_df['polarity'] > 0]\n",
    "tweets_negativos = tweets_df[tweets_df['polarity'] < 0]\n",
    "\n",
    "texto_positivos = ' '.join(tweets_positivos['text'])\n",
    "texto_negativos = ' '.join(tweets_negativos['text'])\n",
    "\n",
    "wordcloud_positivos = WordCloud(width=800, height=400, background_color='white').generate(texto_positivos)\n",
    "wordcloud_negativos = WordCloud(width=800, height=400, background_color='black').generate(texto_negativos)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(wordcloud_positivos, interpolation='bilinear')\n",
    "plt.title('Nube de Palabras - Tweets Positivos')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(wordcloud_negativos, interpolation='bilinear')\n",
    "plt.title('Nube de Palabras - Tweets Negativos')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4ec20d3130a9cacd",
   "metadata": {},
   "source": [
    "### 5. ¿Cómo se distribuyen los tweets según su polaridad en función de la hora del día o el día de la semana?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Convertir la columna timestamp a formato datetime\n",
    "tweets_muestra['timestamp'] = pd.to_datetime(tweets_muestra['timestamp'])\n",
    "tweets_muestra['hour_of_day'] = tweets_muestra['timestamp'].dt.hour\n",
    "tweets_muestra['day_of_week'] = tweets_muestra['timestamp'].dt.day_name()\n",
    "\n",
    "polaridad_por_hora = tweets_muestra.groupby('hour_of_day')['polarity'].mean()\n",
    "\n",
    "#Calculamos la polaridad promedio por día de la semana\n",
    "polaridad_por_dia_semana = tweets_muestra.groupby('day_of_week')['polarity'].mean()\n",
    "\n",
    "\n"
   ],
   "id": "d0619234c99d808f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Graficamos la distribución de polaridad por hora del día\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=polaridad_por_hora.index, y=polaridad_por_hora.values, color='blue')\n",
    "plt.title('Distribución de Polaridad de Tweets por Hora del Día')\n",
    "plt.xlabel('Hora del Día')\n",
    "plt.ylabel('Polaridad Promedio')\n",
    "plt.xticks(range(0, 24))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "275f3a45c76a07ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Graficamos la distribución de polaridad por día de la semana\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=polaridad_por_dia_semana.index, y=polaridad_por_dia_semana.values, palette='viridis')\n",
    "plt.title('Distribución de Polaridad de Tweets por Día de la Semana')\n",
    "plt.xlabel('Día de la Semana')\n",
    "plt.ylabel('Polaridad Promedio')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "225f6b5e7fbf3323",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
